{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекомендательная система на основе Surprise\n",
    "\n",
    "Набор данных - Goodreads books 10k, оригинальный, хранится по адресу расположенный по адресу: https://github.com/zygmuntz/goodbooks-10k    \n",
    "\n",
    "Пакет для построения рекомендательной системы - Surprise\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings: 5976479\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>258</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4081</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>260</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>9296</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2318</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  book_id  rating\n",
       "0        1      258       5\n",
       "1        2     4081       4\n",
       "2        2      260       5\n",
       "3        2     9296       5\n",
       "4        2     2318       3"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.read_csv('./goodbooks-10k-master/ratings.csv') #поставленные оценки\n",
    "print('Ratings:',ratings.shape[0])\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min rating 1, max rating 5\n"
     ]
    }
   ],
   "source": [
    "mn = ratings.rating.min()\n",
    "mx = ratings.rating.max()\n",
    "print(f'Min rating {mn}, max rating {mx}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразовываем данные во внутренний формат и делим на обучающий и тестовый фрагменты. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise.model_selection import train_test_split\n",
    "from surprise import Dataset,  Reader\n",
    "\n",
    "# Преобразовываю данные в формат dataset модуля surprise \n",
    "data = Dataset.load_from_df(ratings[['user_id', 'book_id', 'rating']], Reader(rating_scale=(1,5)))\n",
    "# разбиваю на обучающую и тестовую части\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=13)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В пакет surprise не входят методы оценки precision@k и recall@k. Зададим функцию для расчета. Необходимо отметить, что наличие численного рейтинга позволяет разделить оценки на две группы - понравившиеся и не понраившиеся. Я предполанаю по умолчанию что книги с проставленным рейтингом выше 3.5 понравились, а ниже - нет. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def precision_recall_at_k(predictions, k=10, threshold=3.5):\n",
    "    \"\"\"Return precision and recall at k metrics for each user\"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    user_est_true = defaultdict(list)\n",
    "    for uid, _, true_r, est, _ in predictions:\n",
    "        user_est_true[uid].append((est, true_r))\n",
    "\n",
    "    precisions = dict()\n",
    "    recalls = dict()\n",
    "    for uid, user_ratings in user_est_true.items():\n",
    "\n",
    "        # Sort user ratings by estimated value\n",
    "        user_ratings.sort(key=lambda x: x[0], reverse=True)\n",
    "\n",
    "        # Number of relevant items \n",
    "        n_rel = sum((true_r >= threshold) for (_, true_r) in user_ratings)\n",
    "\n",
    "        # Number of relevant items in top k \n",
    "        #n_rel_k = sum((true_r >= threshold) for (_, true_r) in user_ratings[:k])\n",
    "\n",
    "\n",
    "        # Number of recommended items in top k EQUALS TO K\n",
    "        #n_rec_k = sum((est >= threshold) for (est, _) in user_ratings[:k])\n",
    "\n",
    "        # Number of relevant and recommended items in top k\n",
    "        n_rel_and_rec_k = sum(\n",
    "            ((true_r >= threshold) and (est >= threshold))\n",
    "            for (est, true_r) in user_ratings[:k]\n",
    "        )\n",
    "\n",
    "        # Precision@K: Proportion of recommended relevan items in top k. \n",
    "        # precisions[uid] = n_rel_and_rec_k / n_rec_k if n_rec_k != 0 else 0\n",
    "        precisions[uid] = n_rel_and_rec_k / k if k !=0 else 0\n",
    "\n",
    "        # Recall@K: Proportion of relevant items in top k that are recommended\n",
    "        # When n_rel is 0, Recall is undefined. We here set it to 0.\n",
    "\n",
    "        recalls[uid] = n_rel_and_rec_k / n_rel if n_rel != 0 else 0\n",
    "\n",
    "    return precisions, recalls\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на качество модели с параметрами из коробки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing epoch 0\n",
      "Processing epoch 1\n",
      "Processing epoch 2\n",
      "Processing epoch 3\n",
      "Processing epoch 4\n",
      "Processing epoch 5\n",
      "Processing epoch 6\n",
      "Processing epoch 7\n",
      "Processing epoch 8\n",
      "Processing epoch 9\n",
      "Processing epoch 10\n",
      "Processing epoch 11\n",
      "Processing epoch 12\n",
      "Processing epoch 13\n",
      "Processing epoch 14\n",
      "Processing epoch 15\n",
      "Processing epoch 16\n",
      "Processing epoch 17\n",
      "Processing epoch 18\n",
      "Processing epoch 19\n",
      "RMSE: 0.8292\n",
      "0.8292215296685491\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD, accuracy\n",
    "\n",
    "model = SVD(verbose=True)\n",
    "model.fit(trainset)\n",
    "svd_prediction = model.test(testset)\n",
    "print(accuracy.rmse(svd_prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision @10: 0.7605140011979635\n",
      "Recall @10: 0.5245201679370142\n"
     ]
    }
   ],
   "source": [
    "\n",
    "precisions_10, recall_10 = precision_recall_at_k(svd_prediction, k=10)\n",
    "print('Precision @10:', np.mean(list(precisions_10.values())))\n",
    "print('Recall @10:', np.mean(list(recall_10.values())))\n",
    "\n",
    "#print('Precision @10:', np.mean([ v for v in precisions_10.values()]))\n",
    "#print('Recall @10:', np.mean([ v for v in recall_10.values()]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Резюме \n",
    "\n",
    "5 млн записей предъявили некоторую нагрузку для обработки (примерно 60 секунд на эпоху обучения).  За время обучения на порядок меньше, чем в случае LightFM, получено намного более высокое качество - в среднем 8 книги из 10 соответствуют ожиданиям пользователей (precision@10 = 0.7605). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "addbcdd03704fafbc83443546c5ba4d9ee80e366948352667fd4709d4f794dc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
